[0m[[0m[0mdebug[0m] [0m[0m> Exec(collectAnalyses, None, Some(CommandSource(network-1)))[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Processing event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / collectAnalyses[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: initialized: JsonRpcNotificationMessage(2.0, initialized, {})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///c%3A/DeV/ScalaProjects/wikipedia/src/main/scala/WikipediaRanking.scala","languageId":"scala","version":1,"text":"package wikipedia\n\nimport org.apache.spark._\nimport org.apache.spark.rdd.RDD\n\n\ncase class WikipediaArticle(title: String, text: String) {\n  /**\n    * @return Whether the text of this article mentions `lang` or not\n    * @param lang Language to look for (e.g. \"Scala\")\n    */\n  def mentionsLanguage(lang: String): Boolean = text.split(' ').contains(lang)\n}\n\n/** Main object */\nobject WikipediaRanking {\n  \n  val langs = List(\n    \"JavaScript\", \"Java\", \"PHP\", \"Python\", \"C#\", \"C++\", \"Ruby\", \"CSS\",\n    \"Objective-C\", \"Perl\", \"Scala\", \"Haskell\", \"MATLAB\", \"Clojure\", \"Groovy\")\n\n  // It can sometimes be useful to create a `SparkConf` object to store all the \n  // configuration parameter values for our Spark context, rather than inserting \n  // all the options in the `SparkContext` constructor.\n  val conf: SparkConf = new SparkConf().setMaster(\"local\").setAppName(\"Wikipedia Ranking\")\n\n  // Then, to create the Spark context, we can simply pass the `SparkConf` object \n  // to the `SparkContext` constructor.\n  val sc: SparkContext = new SparkContext(conf)\n\n  /** Main function */\n  def main (args: Array[String]) : Unit = {\n    \n    // Languages ranked according to (1)\n    val langsRanked: List[(String, Int)] =\n      timed(\"Part 1: naive ranking\", rankLangs(langs, wikiRdd))\n\n    // An inverted index mapping languages to wikipedia pages on which they appear\n    def index: RDD[(String, Iterable[WikipediaArticle])] = makeIndex(langs, wikiRdd)\n\n    // Languages ranked according to (2), using the inverted index\n    val langsRanked2: List[(String, Int)]\n      = timed(\"Part 2: ranking using inverted index\", rankLangsUsingIndex(index))\n\n    // Languages ranked according to (3)\n    val langsRanked3: List[(String, Int)]\n      = timed(\"Part 3: ranking using reduceByKey\", rankLangsReduceByKey(langs, wikiRdd))\n\n    // Output the speed of each ranking\n    println(timing)\n    sc.stop()\n\n  }\n\n  // TASK 1 //////////////////////////////////////////////////////////////////////\n\n  val wikiRdd: RDD[WikipediaArticle] = sc.textFile(WikipediaData.filePath).map(line=>WikipediaData.parse(line))\n\n\n  // TASK 2 //////////////////////////////////////////////////////////////////////\n\n\n  // TASK 2: attempt #1 ----------------------------------------------------------\n\n  /** Returns the number of articles in which the language `lang` occurs.\n   */\n  def occurrencesOfLang(lang: String, rdd: RDD[WikipediaArticle]): Int = {\n\n    def seqOp(acc:Int, wa:WikipediaArticle)={\n      if (wa.mentionsLanguage(lang)) acc+1 \n      else acc\n    }\n    rdd.aggregate(0)(seqOp,_+_)\n  }\n\n  //def occurrencesOfLanguage(lang: String, rdd: RDD[WikipediaArticle]): RDD[WikipediaArticle] = rdd.filter(article=>article.mentionsLanguage(lang))\n\n  /** Uses `occurrencesOfLang` to compute the ranking of the languages\n    * (`val langs`) by determining the number of Wikipedia articles that\n    * mention each language at least once.\n    *\n    * IMPORTANT: The result is sorted by number of occurrences, in descending order.\n    */\n  def rankLangs(langs: List[String], rdd: RDD[WikipediaArticle]): List[(String, Int)] = \n    langs.map(lang=>(lang,occurrencesOfLang(lang,rdd))).sortBy(_._2)(Ordering[Int].reverse) //(x,y) => y, we can also sort in descending using sortBy(-_._2) instead\n  // TASK 2: attempt #2 ----------------------------------------------------------\n\n  /** Computes an inverted index of the set of articles, mapping each language\n    * to the Wikipedia pages in which it occurs.\n    */\n  def makeIndex(langs: List[String], rdd: RDD[WikipediaArticle]): RDD[(String, Iterable[WikipediaArticle])] = {\n\n    // You need not do this is small steps.  You can write a one line program.\n    // However, if you would like to break up the task into small parts, here\n    // is what I would recommend.\n\n    // 1. First, create a collection of all pairs (l, wa), where l is a \n    //    language and wa is a Wikipedia article.\n    val pairs: RDD[(String,WikipediaArticle)] = rdd.flatMap(article => {langs.map(lang => (lang, article))})\n    // 2. Second, filter the `pairs` RDD to create a collection of all \n    //    pairs (l, wa) where wa is an article that mentions language l.\n    val mentionedPairs: RDD[(String,WikipediaArticle)] = pairs.filter(pair=> pair._2.mentionsLanguage(pair._1)) // article mentionsLanguage (lang)\n\n    // 3. Finally, return the result of performing a \"group by\" on `mentionedPairs`\n    //    which yields key-value pairs where the key is a language `l` and value is \n    //    the collection of wikipedia articles that mention `l`.\n\n   return mentionedPairs.groupByKey() // <<<<  replace ??? with what you want the `makeIndex` function to return.\n  }\n  // Computes the language ranking using the inverted index.\n  def rankLangsUsingIndex(index: RDD[(String, Iterable[WikipediaArticle])]): List[(String, Int)] = {\n\n      index.mapValues(_.size).sortBy(-_._2).collect().toList\n  }\n\n\n  // TASK 2: attempt #3 ----------------------------------------------------------\n\n  // You might find the helper function `zipLangWithPoint` useful, but it's also possible\n  // to complete this part of the assignment with just the `rankLangsReduceByKey` function.\n\n  // Return a list of `(lang, integer)` pairs containing one pair for each article mentioning `lang`.\n  def zipLangWithPoint(langs: List[String], rdd: RDD[WikipediaArticle]): RDD[(String, Int)] = {\n    \n    rdd.flatMap(article=>langs.withFilter(lang =>article.mentionsLanguage(lang)).map(lang=>(lang,1)))\n  \n  \n  }\n  /** Uses `reduceByKey` to compute the index and the ranking simultaneously.\n    */\n  def rankLangsReduceByKey(langs: List[String], rdd: RDD[WikipediaArticle]): List[(String, Int)] = {\n\n\n    zipLangWithPoint(langs,rdd).reduceByKey(_+_).sortBy(-_._2).collect().toList\n  }\n\n\n  //---- Do not edit below this line -------------------------------------------------------------\n  val timing = new StringBuffer\n  def timed[T](label: String, code: => T): T = {\n    val start = System.currentTimeMillis()\n    val result = code\n    val stop = System.currentTimeMillis()\n    timing.append(s\"Processing $label took ${stop - start} ms.\\n\")\n    result\n  }\n\n}\n"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///c%3A/DeV/ScalaProjects/wikipedia/src/test/scala/WikipediaSuite.scala","languageId":"scala","version":1,"text":"package wikipedia\n\n\nclass WikipediaSuite extends munit.FunSuite {\n\n/* For more information on writing tests, see\n   https://scalameta.org/munit/docs/getting-started.html\n   but here's a simple example:\n\n   test(\"An example test that succeeds\") {\n     val obtained = 42\n     val expected = 42\n     assertEquals(obtained, expected)\n   }\n*/\n\n  def initializeWikipediaRanking(): Boolean =\n    try {\n      WikipediaRanking\n      true\n    } catch {\n      case ex: Throwable =>\n        println(ex.getMessage)\n        ex.printStackTrace()\n        false\n    }\n\n  override def afterAll(): Unit = {\n    assert(initializeWikipediaRanking(), \" -- did you fill in all the values in WikipediaRanking (conf, sc, wikiRdd)?\")\n    import WikipediaRanking._\n    sc.stop()\n  }\n\n  /**\n    * Creates a truncated string representation of a list, adding \", ...)\" if there\n    * are too many elements to show\n    * @param l The list to preview\n    * @param n The number of elements to cut it at\n    * @return A preview of the list, containing at most n elements.\n    */\n  def previewList[A](l: List[A], n: Int = 10): String =\n    if (l.length <= n) l.toString\n    else l.take(n).toString.dropRight(1) + \", ...)\"\n\n  /**\n    * Asserts that all the elements in a assumed list and an expected list are the same,\n    * regardless of order. For a prettier output, assumed and expected should be sorted\n    * with the same ordering.\n    * @param assumed The actual list\n    * @param expected The expected list\n    * @tparam A Type of the list elements\n    */\n  def assertSameElements[A](assumed: List[A], expected: List[A]): Unit = {\n    val assumedSet = assumed.toSet\n    val expectedSet = expected.toSet\n\n    val unexpected = assumedSet -- expectedSet\n    val missing = expectedSet -- assumedSet\n\n    val noUnexpectedElements = unexpected.isEmpty\n    val noMissingElements = missing.isEmpty\n\n    val noMatchString =\n      s\"\"\"\n         |Expected: ${previewList(expected)}\n         |Actual:   ${previewList(assumed)}\"\"\".stripMargin\n\n    assert(noUnexpectedElements,\n      s\"\"\"|$noMatchString\n          |The assumed collection contains some unexpected elements: ${previewList(unexpected.toList, 5)}\"\"\".stripMargin)\n\n    assert(noMissingElements,\n      s\"\"\"|$noMatchString\n          |The assumed collection is missing some expected elements: ${previewList(missing.toList, 5)}\"\"\".stripMargin)\n  }\n\n  // Conditions:\n  // (1) the language stats contain the same elements\n  // (2) they are ordered (and the order doesn't matter if there are several languages with the same count)\n  def assertEquivalentAndOrdered(assumed: List[(String, Int)], expected: List[(String, Int)]): Unit = {\n    // (1)\n    assertSameElements(assumed, expected)\n    // (2)\n    assert(\n      !(assumed zip assumed.tail).exists({ case ((_, occ1), (_, occ2)) => occ1 < occ2 }),\n      \"The assumed elements are not in descending order\"\n    )\n  }\n\n  test(\"'occurrencesOfLang' should work for (specific) RDD with one element\") {\n    assert(initializeWikipediaRanking(), \" -- did you fill in all the values in WikipediaRanking (conf, sc, wikiRdd)?\")\n    import WikipediaRanking._\n    val rdd = sc.parallelize(Seq(WikipediaArticle(\"title\", \"Java Jakarta\")))\n    val res = (occurrencesOfLang(\"Java\", rdd) == 1)\n    assert(res, \"occurrencesOfLang assumed (specific) RDD with one element should equal to 1\")\n  }\n\n  test(\"'rankLangs' should work for RDD with two elements\") {\n    assert(initializeWikipediaRanking(), \" -- did you fill in all the values in WikipediaRanking (conf, sc, wikiRdd)?\")\n    import WikipediaRanking._\n    val langs = List(\"Scala\", \"Java\")\n    val rdd = sc.parallelize(List(WikipediaArticle(\"1\", \"Scala is great\"), WikipediaArticle(\"2\", \"Java is OK, but Scala is cooler\")))\n    val ranked = rankLangs(langs, rdd)\n    val res = ranked.head._1 == \"Scala\"\n    assert(res)\n  }\n\n  test(\"'makeIndex' creates a simple index with two entries\") {\n    assert(initializeWikipediaRanking(), \" -- did you fill in all the values in WikipediaRanking (conf, sc, wikiRdd)?\")\n    import WikipediaRanking._\n    val langs = List(\"Scala\", \"Java\")\n    val articles = List(\n        WikipediaArticle(\"1\",\"Groovy is pretty interesting, and so is Erlang\"),\n        WikipediaArticle(\"2\",\"Scala and Java run on the JVM\"),\n        WikipediaArticle(\"3\",\"Scala is not purely functional\")\n      )\n    val rdd = sc.parallelize(articles)\n    val index = makeIndex(langs, rdd)\n    val res = index.count() == 2\n    assert(res)\n  }\n\n  test(\"'rankLangsUsingIndex' should work for a simple RDD with three elements\") {\n    assert(initializeWikipediaRanking(), \" -- did you fill in all the values in WikipediaRanking (conf, sc, wikiRdd)?\")\n    import WikipediaRanking._\n    val langs = List(\"Scala\", \"Java\")\n    val articles = List(\n        WikipediaArticle(\"1\",\"Groovy is pretty interesting, and so is Erlang\"),\n        WikipediaArticle(\"2\",\"Scala and Java run on the JVM\"),\n        WikipediaArticle(\"3\",\"Scala is not purely functional\")\n      )\n    val rdd = sc.parallelize(articles)\n    val index = makeIndex(langs, rdd)\n    val ranked = rankLangsUsingIndex(index)\n    val res = (ranked.head._1 == \"Scala\")\n    assert(res)\n  }\n\n  test(\"'rankLangsReduceByKey' should work for a simple RDD with four elements\") {\n    assert(initializeWikipediaRanking(), \" -- did you fill in all the values in WikipediaRanking (conf, sc, wikiRdd)?\")\n    import WikipediaRanking._\n    val langs = List(\"Scala\", \"Java\", \"Groovy\", \"Haskell\", \"Erlang\")\n    val articles = List(\n        WikipediaArticle(\"1\",\"Groovy is pretty interesting, and so is Erlang\"),\n        WikipediaArticle(\"2\",\"Scala and Java run on the JVM\"),\n        WikipediaArticle(\"3\",\"Scala is not purely functional\"),\n        WikipediaArticle(\"4\",\"The cool kids like Haskell more than Java\"),\n        WikipediaArticle(\"5\",\"Java is for enterprise developers\")\n      )\n    val rdd = sc.parallelize(articles)\n    val ranked = rankLangsReduceByKey(langs, rdd)\n    val res = (ranked.head._1 == \"Java\")\n    assert(res)\n  }\n\n\n}\n"}})[0m
[0m[[0m[0mdebug[0m] [0m[0manalysis location (C:\DeV\ScalaProjects\wikipedia\target\scala-2.13\zinc\inc_compile_2.13.zip,true)[0m
[0m[[0m[32msuccess[0m] [0m[0mTotal time: 1 s, completed 21-Apr-2023, 12:14:10 PM[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Done event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(shell, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled request received: shutdown: JsonRpcRequestMessage(2.0, ♨1, shutdown, null})[0m
